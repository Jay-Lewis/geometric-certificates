{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.conda/envs/DeepL/lib/python3.7/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In this example, we build a binary MNIST classifier and then run GeoCert on several test points.\n",
    "'''\n",
    "\n",
    "# =====================\n",
    "# Imports\n",
    "# =====================\n",
    "# %load_ext line_profiler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../mister_ed') # library for adversarial examples\n",
    "\n",
    "import geocert_oop as geo\n",
    "from plnn import PLNN\n",
    "import _polytope_ as _poly_\n",
    "from _polytope_ import Polytope, Face\n",
    "import utilities as utils\n",
    "import os\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import adversarial_perturbations as ap \n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import adversarial_attacks as aa\n",
    "import utils.pytorch_utils as me_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import mnist.mnist_loader as  ml \n",
    "mnist_trainset = ml.load_mnist_data('train')\n",
    "mnist_valset = ml.load_mnist_data('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to select only a subset of digits from MNIST datasets\n",
    "def select_digits(dataset, digits, mb_size=128, remap_label=True):\n",
    "    if remap_label and len(digits) <= 2:\n",
    "        def label_map(labels):\n",
    "            return (labels == digits[0]).unsqueeze(1)\n",
    "    elif remap_label and len(digits) > 2:\n",
    "        raise NotImplementedError(\"Only handling between 2 types of digits for now\")\n",
    "    else:\n",
    "        label_map = lambda x: x\n",
    "            \n",
    "    sel_data, sel_labels = [], [] \n",
    "    for data, labels in dataset:\n",
    "        mask = labels == -1\n",
    "        for digit in digits:\n",
    "            mask += (labels == digit)\n",
    "        #mask = (labels == 7) + (labels == 1)\n",
    "        masked_data = data.masked_select(mask.view(-1, 1, 1, 1).expand(data.shape)).view(-1, 1, 28, 28)\n",
    "        masked_labels = labels.masked_select(mask)\n",
    "        sel_data.append(masked_data)\n",
    "        sel_labels.append(masked_labels)\n",
    "        \n",
    "    # Then concatenate and resplit into minibatches of size 128\n",
    "    cat_data = torch.cat(sel_data)\n",
    "    cat_labels = torch.cat(sel_labels)\n",
    "    full_dataset = [] \n",
    "    num_mb = int(len(cat_labels) / mb_size + 1)\n",
    "    for i in range(num_mb):\n",
    "        full_dataset.append((cat_data[mb_size * i: mb_size * (i + 1)], \n",
    "                             label_map(cat_labels[mb_size * i: mb_size * (i + 1)]).squeeze().long()))\n",
    "    return full_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset containing only 1's and 7's\n",
    "MINIBATCH_SIZE = 128\n",
    "os_trainset = select_digits(mnist_trainset, [1, 7], mb_size=MINIBATCH_SIZE)\n",
    "os_valset = select_digits(mnist_valset, [1, 7], mb_size=MINIBATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to train and evaluate a network \n",
    "\n",
    "def l1_loss(net):\n",
    "    return sum([_.norm(p=1) for _ in net.parameters() if _.dim() > 1])\n",
    "\n",
    "def train(net, trainset, num_epochs):\n",
    "    opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        err_acc = 0\n",
    "        err_count = 0\n",
    "        for data, labels in trainset:\n",
    "            output = net(Variable(data.view(-1, 784)))\n",
    "            l = nn.CrossEntropyLoss()(output, Variable(labels)).view([1])\n",
    "            l1_scale = torch.Tensor([2e-3])\n",
    "            l += l1_scale * l1_loss(net).view([1])\n",
    "            \n",
    "            err_acc += (output.max(1)[1].data != labels).float().mean() \n",
    "            err_count += 1\n",
    "            opt.zero_grad() \n",
    "            (l).backward() \n",
    "            opt.step() \n",
    "        print(\"(%02d) error:\" % epoch, err_acc / err_count)\n",
    "            \n",
    "        \n",
    "def test_acc(net, valset):\n",
    "    err_acc = 0 \n",
    "    err_count = 0 \n",
    "    for data, labels in valset:\n",
    "        n = data.shape[0]\n",
    "        output = net(Variable(data.view(-1, 784)))\n",
    "        err_acc += (output.max(1)[1].data != labels).float().mean() * n\n",
    "        err_count += n\n",
    "        \n",
    "    print(\"Accuracy of: %.03f\" % (1 - (err_acc / err_count).item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 10, 50, 10, 2]\n",
      "(00) error: tensor(0.0817)\n",
      "(01) error: tensor(0.0091)\n",
      "(02) error: tensor(0.0079)\n",
      "(03) error: tensor(0.0074)\n",
      "(04) error: tensor(0.0070)\n",
      "(05) error: tensor(0.0066)\n",
      "(06) error: tensor(0.0061)\n",
      "(07) error: tensor(0.0061)\n",
      "(08) error: tensor(0.0060)\n",
      "(09) error: tensor(0.0059)\n",
      "Accuracy of: 0.990\n"
     ]
    }
   ],
   "source": [
    "# Define the network architecture.\n",
    "MNIST_DIM = 784\n",
    "network = PLNN([MNIST_DIM, 10, 50, 10, 2])\n",
    "net = network.net\n",
    "\n",
    "# Train and evaluate the network \n",
    "train(net, os_trainset, 10)\n",
    "test_acc(net, os_valset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5c10e7390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With a trained net, we can pick some examples and run GeoCert on them \n",
    "EXAMPLE_NUMBER = 7\n",
    "data, labels = next(iter(os_valset)) # select a minibatch of the validation set\n",
    "example = data[EXAMPLE_NUMBER]\n",
    "print(example.shape)\n",
    "plt.gray()\n",
    "plt.imshow(example.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upper bound computation\n",
      "Upper bound of 0.2984864115715027 in 5.02 seconds\n",
      "---Initial Polytope---\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'domain_infeasible': 11, 'dead_constraints': 59, 'num_lps': 0}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Face' object has no attribute '_domain_structure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-842a739ac1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m lp_dist, cw_bound, cw_example, adver_example, boundary = geocert.min_dist(example.view(1, -1), lp_norm='l_2', \n\u001b[0;32m---> 10\u001b[0;31m                                                                           compute_upper_bound=True)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geometric-certificates/geocert_oop.py\u001b[0m in \u001b[0;36mmin_dist\u001b[0;34m(self, x, lp_norm, compute_upper_bound)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                          \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                                          dead_constraints=self.dead_constraints)\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geometric-certificates/geocert_oop.py\u001b[0m in \u001b[0;36m_update_step\u001b[0;34m(self, poly, popped_facet)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Step 3) Adds the adversarial constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfacet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madv_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mfacet_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlp_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             heap_el = HeapElement(facet_distance, facet, facet_type='decision',\n\u001b[1;32m    387\u001b[0m                                   exact_or_estimate='exact')\n",
      "\u001b[0;32m~/Projects/geometric-certificates/_polytope_.py\u001b[0m in \u001b[0;36ml2_dist\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1124\u001b[0m             as well as the optimal value of the program\"\"\"\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_domain_structure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_constraints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Face' object has no attribute '_domain_structure'"
     ]
    }
   ],
   "source": [
    "from importlib import reload \n",
    "reload(geo)\n",
    "# Builds an object used to to hold algorithm parameters\n",
    "geocert = geo.IncrementalGeoCert(network, verbose=True, config_fxn='parallel', \n",
    "                                 config_fxn_kwargs={'num_jobs': 1})\n",
    "\n",
    "# Runs the algorithm\n",
    "start = time.time()\n",
    "lp_dist, cw_bound, cw_example, adver_example, boundary = geocert.min_dist(example.view(1, -1), lp_norm='l_2', \n",
    "                                                                          compute_upper_bound=True)\n",
    "end = time.time() \n",
    "\n",
    "# Prints outputs\n",
    "print(\"Found an adversarial example at dist\", lp_dist, \" in %.02f seconds \" % (end - start))\n",
    "if cw_bound is not None:\n",
    "    print(\"Carlini-Wagner attack found example at distance\", cw_bound)\n",
    "original_logits = network(example)\n",
    "adver_logits = network(torch.Tensor(adver_example).view(1, 28, 28))\n",
    "print(\"Original output was \", original_logits.data.cpu().numpy())\n",
    "print(\"Adversarial output was \", adver_logits.data.cpu().numpy())\n",
    "\n",
    "# Display the adversarial examples \n",
    "to_displays = [(example.cpu().numpy().reshape((28, 28)), 'Original'), \n",
    "               (adver_example.reshape((28, 28)), 'GeoCert')]\n",
    "if cw_example is not None: \n",
    "    to_displays.append((cw_out.reshape((28, 28)), 'Carlini-Wagner L2'))\n",
    "f, axarr = plt.subplots(1, len(to_displays), figsize=(12, 12))\n",
    "for i in range(len(to_displays)):\n",
    "    axarr[i].imshow(to_displays[i][0])\n",
    "    axarr[i].set_title(to_displays[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
