{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.conda/envs/DeepL/lib/python3.7/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In this example, we build a binary MNIST classifier and then run GeoCert on several test points.\n",
    "'''\n",
    "\n",
    "# =====================\n",
    "# Imports\n",
    "# =====================\n",
    "# %load_ext line_profiler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../mister_ed') # library for adversarial examples\n",
    "\n",
    "import geocert_oop as geo\n",
    "from plnn import PLNN\n",
    "import _polytope_ as _poly_\n",
    "from _polytope_ import Polytope, Face\n",
    "import utilities as utils\n",
    "import os\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import adversarial_perturbations as ap \n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import adversarial_attacks as aa\n",
    "import utils.pytorch_utils as me_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import mnist.mnist_loader as  ml \n",
    "mnist_trainset = ml.load_mnist_data('train')\n",
    "mnist_valset = ml.load_mnist_data('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to select only a subset of digits from MNIST datasets\n",
    "def select_digits(dataset, digits, mb_size=128, remap_label=True):\n",
    "    if remap_label and len(digits) <= 2:\n",
    "        def label_map(labels):\n",
    "            return (labels == digits[0]).unsqueeze(1)\n",
    "    elif remap_label and len(digits) > 2:\n",
    "        raise NotImplementedError(\"Only handling between 2 types of digits for now\")\n",
    "    else:\n",
    "        label_map = lambda x: x\n",
    "            \n",
    "    sel_data, sel_labels = [], [] \n",
    "    for data, labels in dataset:\n",
    "        mask = labels == -1\n",
    "        for digit in digits:\n",
    "            mask += (labels == digit)\n",
    "        #mask = (labels == 7) + (labels == 1)\n",
    "        masked_data = data.masked_select(mask.view(-1, 1, 1, 1).expand(data.shape)).view(-1, 1, 28, 28)\n",
    "        masked_labels = labels.masked_select(mask)\n",
    "        sel_data.append(masked_data)\n",
    "        sel_labels.append(masked_labels)\n",
    "        \n",
    "    # Then concatenate and resplit into minibatches of size 128\n",
    "    cat_data = torch.cat(sel_data)\n",
    "    cat_labels = torch.cat(sel_labels)\n",
    "    full_dataset = [] \n",
    "    num_mb = int(len(cat_labels) / mb_size + 1)\n",
    "    for i in range(num_mb):\n",
    "        full_dataset.append((cat_data[mb_size * i: mb_size * (i + 1)], \n",
    "                             label_map(cat_labels[mb_size * i: mb_size * (i + 1)]).squeeze().long()))\n",
    "    return full_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset containing only 1's and 7's\n",
    "MINIBATCH_SIZE = 128\n",
    "os_trainset = select_digits(mnist_trainset, [1, 7], mb_size=MINIBATCH_SIZE)\n",
    "os_valset = select_digits(mnist_valset, [1, 7], mb_size=MINIBATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to train and evaluate a network \n",
    "\n",
    "def l1_loss(net):\n",
    "    return sum([_.norm(p=1) for _ in net.parameters() if _.dim() > 1])\n",
    "\n",
    "def train(net, trainset, num_epochs):\n",
    "    opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        err_acc = 0\n",
    "        err_count = 0\n",
    "        for data, labels in trainset:\n",
    "            output = net(Variable(data.view(-1, 784)))\n",
    "            l = nn.CrossEntropyLoss()(output, Variable(labels)).view([1])\n",
    "            l1_scale = torch.Tensor([2e-3])\n",
    "            l += l1_scale * l1_loss(net).view([1])\n",
    "            \n",
    "            err_acc += (output.max(1)[1].data != labels).float().mean() \n",
    "            err_count += 1\n",
    "            opt.zero_grad() \n",
    "            (l).backward() \n",
    "            opt.step() \n",
    "        print(\"(%02d) error:\" % epoch, err_acc / err_count)\n",
    "            \n",
    "        \n",
    "def test_acc(net, valset):\n",
    "    err_acc = 0 \n",
    "    err_count = 0 \n",
    "    for data, labels in valset:\n",
    "        n = data.shape[0]\n",
    "        output = net(Variable(data.view(-1, 784)))\n",
    "        err_acc += (output.max(1)[1].data != labels).float().mean() * n\n",
    "        err_count += n\n",
    "        \n",
    "    print(\"Accuracy of: %.03f\" % (1 - (err_acc / err_count).item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 10, 50, 10, 2]\n",
      "(00) error: tensor(0.0657)\n",
      "(01) error: tensor(0.0105)\n",
      "(02) error: tensor(0.0092)\n",
      "(03) error: tensor(0.0086)\n",
      "(04) error: tensor(0.0076)\n",
      "(05) error: tensor(0.0071)\n",
      "(06) error: tensor(0.0066)\n",
      "(07) error: tensor(0.0063)\n",
      "(08) error: tensor(0.0060)\n",
      "(09) error: tensor(0.0059)\n",
      "Accuracy of: 0.984\n"
     ]
    }
   ],
   "source": [
    "# Define the network architecture.\n",
    "MNIST_DIM = 784\n",
    "network = PLNN([MNIST_DIM, 10, 50, 10, 2])\n",
    "net = network.net\n",
    "\n",
    "# Train and evaluate the network \n",
    "train(net, os_trainset, 10)\n",
    "test_acc(net, os_valset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ae113f240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With a trained net, we can pick some examples and run GeoCert on them \n",
    "EXAMPLE_NUMBER = 7\n",
    "data, labels = next(iter(os_valset)) # select a minibatch of the validation set\n",
    "example = data[EXAMPLE_NUMBER]\n",
    "print(example.shape)\n",
    "plt.gray()\n",
    "plt.imshow(example.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upper bound computation\n",
      "Upper bound of 0.4099297821521759 in 5.42 seconds\n",
      "---Initial Polytope---\n",
      "Num facets:  3\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 14, 'num_lps': 3}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.045991211915694025   |   0.4099297821521759\n",
      "Num facets:  2\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 12, 'num_lps': 5, 'infeasible': 3}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.05910952730520718   |   0.4099297821521759\n",
      "Num facets:  2\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 13, 'num_lps': 4, 'infeasible': 2}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.06246077684572435   |   0.4099297821521759\n",
      "Num facets:  3\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 14, 'num_lps': 3}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.06466255798161165   |   0.4099297821521759\n",
      "Num facets:  2\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 15, 'num_lps': 2}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.06523533424705065   |   0.4099297821521759\n",
      "Num facets:  1\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 16, 'num_lps': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.0719213705455759   |   0.4099297821521759\n",
      "Num facets:  2\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 15, 'num_lps': 2}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.07324925029256249   |   0.4099297821521759\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'dead_constraints': 53, 'domain_infeasible': 17, 'num_lps': 0}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.0771466871345232   |   0.20235757374873073\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 6, 'num_lps': 2, 'infeasible': 1, 'seen before': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.10047602308790107   |   0.20235757374873073\n",
      "Num facets:  1\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 7, 'num_lps': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.10728979499273564   |   0.20235757374873073\n",
      "Num facets:  1\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 6, 'num_lps': 2, 'seen before': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.1100581672197154   |   0.20235757374873073\n",
      "Num facets:  1\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 6, 'num_lps': 2, 'seen before': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.11577218024919689   |   0.20235757374873073\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 7, 'num_lps': 1, 'seen before': 1}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.11577276905676334   |   0.20235757374873073\n",
      "We've already seen that polytope\n",
      "---Opening New Polytope---\n",
      "Bounds  0.16378496217202201   |   0.20235757374873073\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 6, 'num_lps': 2, 'seen before': 2}\n",
      "---Opening New Polytope---\n",
      "Bounds  0.18247576867963583   |   0.20235757374873073\n",
      "Num facets:  0\n",
      "REJECT DICT:  {'dead_constraints': 62, 'domain_infeasible': 6, 'num_lps': 2, 'infeasible': 1, 'seen before': 1}\n",
      "----------Minimal Projection Generated----------\n",
      "DIST:  0.20235757374873073\n",
      "Found an adversarial example at dist 0.20235757374873073  in 28.44 seconds \n",
      "Carlini-Wagner attack found example at distance 0.4099297821521759\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Type must be a sub-type of ndarray type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae935b2c07c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcw_bound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Carlini-Wagner attack found example at distance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0moriginal_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madver_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0madver_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madver_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DeepL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geometric-certificates/plnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload \n",
    "reload(geo)\n",
    "# Builds an object used to to hold algorithm parameters\n",
    "geocert = geo.IncrementalGeoCert(network, verbose=True, config_fxn='parallel', \n",
    "                                 config_fxn_kwargs={'num_jobs': 1})\n",
    "\n",
    "# Runs the algorithm\n",
    "start = time.time()\n",
    "lp_dist, cw_bound, cw_example, adver_example, boundary = geocert.min_dist(example.view(1, -1), lp_norm='l_inf', \n",
    "                                                                          compute_upper_bound=True)\n",
    "\n",
    "\n",
    "for example in adver_example[0:20]:\n",
    "    plt.imshow(example.reshape((28, 28)))\n",
    "\n",
    "adver_example = adver_example[0]\n",
    "\n",
    "end = time.time() \n",
    "\n",
    "# Prints outputs\n",
    "print(\"Found an adversarial example at dist\", lp_dist, \" in %.02f seconds \" % (end - start))\n",
    "if cw_bound is not None:\n",
    "    print(\"Carlini-Wagner attack found example at distance\", cw_bound)\n",
    "original_logits = network(example)\n",
    "print(np.shape(adver_example))\n",
    "adver_logits = network(torch.Tensor(adver_example).view(1, 28, 28))\n",
    "print(\"Original output was \", original_logits.data.cpu().numpy())\n",
    "print(\"Adversarial output was \", adver_logits.data.cpu().numpy())\n",
    "\n",
    "# Display the adversarial examples \n",
    "to_displays = [(example.cpu().numpy().reshape((28, 28)), 'Original'), \n",
    "               (adver_example.reshape((28, 28)), 'GeoCert')]\n",
    "if cw_example is not None: \n",
    "    to_displays.append((cw_example.reshape((28, 28)), 'Carlini-Wagner L2'))\n",
    "f, axarr = plt.subplots(1, len(to_displays), figsize=(12, 12))\n",
    "for i in range(len(to_displays)):\n",
    "    axarr[i].imshow(to_displays[i][0])\n",
    "    axarr[i].set_title(to_displays[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
