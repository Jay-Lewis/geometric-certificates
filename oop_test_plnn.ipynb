{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanm/.virtualenvs/myvenv/lib/python3.7/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Imports\n",
    "# =====================\n",
    "%load_ext line_profiler\n",
    "\n",
    "from geocert import compute_boundary_batch, batch_GeoCert, incremental_GeoCert\n",
    "import geocert_oop as geo\n",
    "from plnn import PLNN\n",
    "import _polytope_ as _poly_\n",
    "from _polytope_ import Polytope, Face, from_polytope_dict\n",
    "import utilities as utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "# from convex_adversarial import robust_loss\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('mister_ed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mister_ed.adversarial_attacks as aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Generating Training Points============\n",
      "===============Points Generated============\n"
     ]
    }
   ],
   "source": [
    "# apply incremental geocert to a normal and l1-regularized classifier. Finds maximal l_p balls\n",
    "# for random points in R^2.\n",
    "\n",
    "# ==================================\n",
    "# Generate Training Points\n",
    "# ==================================\n",
    "\n",
    "print('===============Generating Training Points============')\n",
    "# random points at least 2r apart\n",
    "m = 12\n",
    "np.random.seed(3)\n",
    "x = [np.random.uniform(size=(2))]\n",
    "r = 0.16\n",
    "while(len(x) < m):\n",
    "    p = np.random.uniform(size=(2))\n",
    "    if min(np.abs(p-a).sum() for a in x) > 2*r:\n",
    "        x.append(p)\n",
    "# r = 0.145\n",
    "epsilon = r/2\n",
    "\n",
    "X = torch.Tensor(np.array(x))\n",
    "torch.manual_seed(1)\n",
    "y = (torch.rand(m)+0.5).long()\n",
    "\n",
    "print('===============Points Generated============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============Initializing Network============\n",
      "Sequential(\n",
      "  (1): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "===============Training Network with Regularization============\n",
      "error:  tensor(0.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanm/.virtualenvs/myvenv/lib/python3.7/site-packages/torch/tensor.py:263: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Initialize Network\n",
    "# ==================================\n",
    "\n",
    "print('===============Initializing Network============')\n",
    "network = PLNN([2, 10, 50, 10, 2])\n",
    "net = network.net\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# Train Network\n",
    "# ==================================\n",
    "\n",
    "def l1_loss(net):\n",
    "\n",
    "    return sum([_.norm(p=1) for _ in net.parameters() if _.dim() > 1])\n",
    "\n",
    "\n",
    "print('===============Training Network with Regularization============')\n",
    "opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "for i in range(1000):\n",
    "    out = net(Variable(X))\n",
    "    l = nn.CrossEntropyLoss()(out, Variable(y)).view([1])\n",
    "\n",
    "    l1_scale = torch.Tensor([1e-4])\n",
    "    l += l1_scale * l1_loss(net).view([1])\n",
    "\n",
    "    err = (out.max(1)[1].data != y).float().mean()\n",
    "    opt.zero_grad()\n",
    "    (l).backward()\n",
    "    opt.step()\n",
    "\n",
    "print('error: ', err)\n",
    "\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# Visualize:  regularized classifier boundary\n",
    "# ==================================\n",
    "\n",
    "XX, YY = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "X0 = Variable(torch.Tensor(np.stack([np.ravel(XX), np.ravel(YY)]).T))\n",
    "y0 = network(X0)\n",
    "ZZ = (y0[:,0] - y0[:,1]).resize(100, 100).data.numpy()\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8,8))\n",
    "ax.contourf(XX,YY,-ZZ, cmap=\"coolwarm\", levels=np.linspace(-1000,1000,3))\n",
    "ax.scatter(X.numpy()[:,0], X.numpy()[:,1], c=y.numpy(), cmap=\"coolwarm\", s=70)\n",
    "ax.axis(\"equal\")\n",
    "ax.axis([0, 1, 0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'plots/oop_plnn_l2/')\n",
    "geocert = geo.IncrementalGeoCert(network, verbose=True, display=True, save_dir=save_dir, \n",
    "                                 ax=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7000, 0.6000],\n",
      "        [0.5000, 0.5000]])\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "examples = torch.Tensor([[0.7, 0.6], \n",
    "                         [0.5, 0.5]])\n",
    "labels = network(examples).max(1)[1]\n",
    "\n",
    "print(examples)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'adversarial_attacks' from 'mister_ed/adversarial_attacks.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import adversarial_perturbations as ap \n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import adversarial_attacks as aa\n",
    "import utils.pytorch_utils as me_utils\n",
    "from importlib import reload \n",
    "reload(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIST <class 'loss_functions.L2Regularization'> True <class 'loss_functions.ReferenceRegularizer'>\n",
      "Starting binary_search_step 00...\n",
      "Optim search: 100, Loss: tensor(61.4530, grad_fn=<ThAddBackward>)\n",
      "(iteration 100):  100.0 correct\n",
      "Optim search: 200, Loss: tensor(52.1420, grad_fn=<ThAddBackward>)\n",
      "(iteration 200):  100.0 correct\n",
      "Optim search: 300, Loss: tensor(42.8309, grad_fn=<ThAddBackward>)\n",
      "(iteration 300):  100.0 correct\n",
      "Optim search: 400, Loss: tensor(33.5200, grad_fn=<ThAddBackward>)\n",
      "(iteration 400):  100.0 correct\n",
      "Optim search: 500, Loss: tensor(24.2092, grad_fn=<ThAddBackward>)\n",
      "(iteration 500):  100.0 correct\n",
      "Optim search: 600, Loss: tensor(19.3355, grad_fn=<ThAddBackward>)\n",
      "(iteration 600):  50.0 correct\n",
      "Optim search: 700, Loss: tensor(14.6799, grad_fn=<ThAddBackward>)\n",
      "(iteration 700):  50.0 correct\n",
      "Optim search: 800, Loss: tensor(10.0243, grad_fn=<ThAddBackward>)\n",
      "(iteration 800):  50.0 correct\n",
      "Optim search: 900, Loss: tensor(5.3687, grad_fn=<ThAddBackward>)\n",
      "(iteration 900):  50.0 correct\n",
      "Optim search: 1000, Loss: tensor(0.7131, grad_fn=<ThAddBackward>)\n",
      "(iteration 1000):  50.0 correct\n",
      "...stopping early on binary_search_step 00  after 1014 iterations\n",
      "Starting binary_search_step 01...\n",
      "Optim search: 100, Loss: tensor(30.7337, grad_fn=<ThAddBackward>)\n",
      "(iteration 100):  100.0 correct\n",
      "Optim search: 200, Loss: tensor(26.0853, grad_fn=<ThAddBackward>)\n",
      "(iteration 200):  100.0 correct\n",
      "Optim search: 300, Loss: tensor(21.4370, grad_fn=<ThAddBackward>)\n",
      "(iteration 300):  100.0 correct\n",
      "Optim search: 400, Loss: tensor(16.7886, grad_fn=<ThAddBackward>)\n",
      "(iteration 400):  100.0 correct\n",
      "Optim search: 500, Loss: tensor(12.1403, grad_fn=<ThAddBackward>)\n",
      "(iteration 500):  100.0 correct\n",
      "Optim search: 600, Loss: tensor(9.7073, grad_fn=<ThAddBackward>)\n",
      "(iteration 600):  50.0 correct\n",
      "Optim search: 700, Loss: tensor(7.3830, grad_fn=<ThAddBackward>)\n",
      "(iteration 700):  50.0 correct\n",
      "Optim search: 800, Loss: tensor(5.0587, grad_fn=<ThAddBackward>)\n",
      "(iteration 800):  50.0 correct\n",
      "Optim search: 900, Loss: tensor(2.7344, grad_fn=<ThAddBackward>)\n",
      "(iteration 900):  50.0 correct\n",
      "Optim search: 1000, Loss: tensor(0.4101, grad_fn=<ThAddBackward>)\n",
      "(iteration 1000):  50.0 correct\n",
      "...stopping early on binary_search_step 01  after 1015 iterations\n",
      "Starting binary_search_step 02...\n",
      "Optim search: 100, Loss: tensor(36.6587, grad_fn=<ThAddBackward>)\n",
      "(iteration 100):  100.0 correct\n",
      "Optim search: 200, Loss: tensor(32.0103, grad_fn=<ThAddBackward>)\n",
      "(iteration 200):  100.0 correct\n",
      "Optim search: 300, Loss: tensor(27.3619, grad_fn=<ThAddBackward>)\n",
      "(iteration 300):  100.0 correct\n",
      "Optim search: 400, Loss: tensor(22.7136, grad_fn=<ThAddBackward>)\n",
      "(iteration 400):  100.0 correct\n",
      "Optim search: 500, Loss: tensor(18.0652, grad_fn=<ThAddBackward>)\n",
      "(iteration 500):  100.0 correct\n",
      "Optim search: 600, Loss: tensor(14.5214, grad_fn=<ThAddBackward>)\n",
      "(iteration 600):  50.0 correct\n",
      "Optim search: 700, Loss: tensor(11.0314, grad_fn=<ThAddBackward>)\n",
      "(iteration 700):  50.0 correct\n",
      "Optim search: 800, Loss: tensor(7.5414, grad_fn=<ThAddBackward>)\n",
      "(iteration 800):  50.0 correct\n",
      "Optim search: 900, Loss: tensor(4.0514, grad_fn=<ThAddBackward>)\n",
      "(iteration 900):  50.0 correct\n",
      "Optim search: 1000, Loss: tensor(0.5614, grad_fn=<ThAddBackward>)\n",
      "(iteration 1000):  50.0 correct\n",
      "...stopping early on binary_search_step 02  after 1014 iterations\n",
      "Starting binary_search_step 03...\n",
      "Optim search: 100, Loss: tensor(39.6212, grad_fn=<ThAddBackward>)\n",
      "(iteration 100):  100.0 correct\n",
      "Optim search: 200, Loss: tensor(34.9729, grad_fn=<ThAddBackward>)\n",
      "(iteration 200):  100.0 correct\n",
      "Optim search: 300, Loss: tensor(30.3244, grad_fn=<ThAddBackward>)\n",
      "(iteration 300):  100.0 correct\n",
      "Optim search: 400, Loss: tensor(25.6761, grad_fn=<ThAddBackward>)\n",
      "(iteration 400):  100.0 correct\n",
      "Optim search: 500, Loss: tensor(21.0277, grad_fn=<ThAddBackward>)\n",
      "(iteration 500):  100.0 correct\n",
      "Optim search: 600, Loss: tensor(16.9284, grad_fn=<ThAddBackward>)\n",
      "(iteration 600):  50.0 correct\n",
      "Optim search: 700, Loss: tensor(12.8556, grad_fn=<ThAddBackward>)\n",
      "(iteration 700):  50.0 correct\n",
      "Optim search: 800, Loss: tensor(8.7827, grad_fn=<ThAddBackward>)\n",
      "(iteration 800):  50.0 correct\n",
      "Optim search: 900, Loss: tensor(4.7098, grad_fn=<ThAddBackward>)\n",
      "(iteration 900):  50.0 correct\n",
      "Optim search: 1000, Loss: tensor(0.6369, grad_fn=<ThAddBackward>)\n",
      "(iteration 1000):  50.0 correct\n",
      "...stopping early on binary_search_step 03  after 1014 iterations\n",
      "Starting binary_search_step 04...\n",
      "Optim search: 100, Loss: tensor(35.7813, grad_fn=<ThAddBackward>)\n",
      "(iteration 100):  100.0 correct\n",
      "Optim search: 200, Loss: tensor(31.7158, grad_fn=<ThAddBackward>)\n",
      "(iteration 200):  100.0 correct\n",
      "Optim search: 300, Loss: tensor(27.6502, grad_fn=<ThAddBackward>)\n",
      "(iteration 300):  100.0 correct\n",
      "Optim search: 400, Loss: tensor(23.5846, grad_fn=<ThAddBackward>)\n",
      "(iteration 400):  100.0 correct\n",
      "Optim search: 500, Loss: tensor(19.5191, grad_fn=<ThAddBackward>)\n",
      "(iteration 500):  100.0 correct\n",
      "Optim search: 600, Loss: tensor(15.7248, grad_fn=<ThAddBackward>)\n",
      "(iteration 600):  50.0 correct\n",
      "Optim search: 700, Loss: tensor(11.9433, grad_fn=<ThAddBackward>)\n",
      "(iteration 700):  50.0 correct\n",
      "Optim search: 800, Loss: tensor(8.1617, grad_fn=<ThAddBackward>)\n",
      "(iteration 800):  50.0 correct\n",
      "Optim search: 900, Loss: tensor(4.3803, grad_fn=<ThAddBackward>)\n",
      "(iteration 900):  50.0 correct\n",
      "Optim search: 1000, Loss: tensor(0.5989, grad_fn=<ThAddBackward>)\n",
      "(iteration 1000):  50.0 correct\n",
      "...stopping early on binary_search_step 04  after 1014 iterations\n",
      "\n",
      " Ending attack\n",
      "Successful attacks for 002/002 examples in CONTINUOUS\n"
     ]
    }
   ],
   "source": [
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                 'lp_bound': 1.0})\n",
    "normalizer = me_utils.IdentityNormalize() \n",
    "distance_fxn = lf.L2Regularization\n",
    "carlini_loss = lf.CWLossF6\n",
    "cwl2_attack = aa.CarliniWagner(net, normalizer, delta_threat, distance_fxn, carlini_loss)\n",
    "\n",
    "attack_kwargs = {'warm_start': False, 'num_optim_steps': 2000, 'num_bin_search_steps': 5,\n",
    "                 'initial_lambda': 10, 'verbose': True}\n",
    "pert_out = cwl2_attack.attack(examples, labels, **attack_kwargs)\n",
    "#adv_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5985, 0.4985],\n",
       "        [0.5506, 0.5505]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_out.adversarial_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
